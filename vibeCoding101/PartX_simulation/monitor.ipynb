{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7831e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m base_dir = Path(\u001b[34;43m__file__\u001b[39;49m).parent / \u001b[33m'\u001b[39m\u001b[33mmonitor_outputs_60min\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m ANALYSIS_DIR = BASE / \u001b[33m'\u001b[39m\u001b[33manalysis\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      8\u001b[39m ANALYSIS_DIR.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "base_dir = Path(__file__).parent / 'monitor_outputs_60min'\n",
    "ANALYSIS_DIR = BASE / 'analysis'\n",
    "ANALYSIS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 找最新的 monitor_summary CSV\n",
    "csvs = sorted(BASE.glob('monitor_summary_*.csv'))\n",
    "if not csvs:\n",
    "    raise SystemExit('No monitor_summary CSV found in ' + str(BASE))\n",
    "csv_path = csvs[-1]\n",
    "print('Using', csv_path.name)\n",
    "\n",
    "df = pd.read_csv(csv_path, parse_dates=['snapshot_ts','eta','data_timestamp'])\n",
    "# ensure tz-aware\n",
    "if df['snapshot_ts'].dt.tz is None:\n",
    "    df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts']).dt.tz_localize('UTC')\n",
    "if df['eta'].dt.tz is None:\n",
    "    df['eta'] = pd.to_datetime(df['eta']).dt.tz_localize('Asia/Hong_Kong')\n",
    "\n",
    "# normalize both to Asia/Hong_Kong for wait calculations\n",
    "df['snapshot_local'] = df['snapshot_ts'].dt.tz_convert('Asia/Hong_Kong')\n",
    "df['eta_local'] = df['eta'].dt.tz_convert('Asia/Hong_Kong')\n",
    "\n",
    "df['wait_s'] = (df['eta_local'] - df['snapshot_local']).dt.total_seconds()\n",
    "# floor snapshot to minute for per-minute aggregation\n",
    "df['snapshot_min'] = df['snapshot_local'].dt.floor('T')\n",
    "\n",
    "summary = {}\n",
    "# per-stop analyses\n",
    "for stop_id, g in df.groupby('queried_stop_id'):\n",
    "    out_prefix = ANALYSIS_DIR / f'{stop_id}'\n",
    "    # mean wait per minute\n",
    "    per_min = g.groupby('snapshot_min')['wait_s'].mean()\n",
    "    counts_min = g.groupby('snapshot_min').size()\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    per_min.plot(title=f'Mean wait (s) per minute - {stop_id}')\n",
    "    plt.ylabel('mean wait (s)')\n",
    "    plt.xlabel('snapshot_min')\n",
    "    plt.tight_layout()\n",
    "    fig1 = ANALYSIS_DIR / f'mean_wait_per_minute_{stop_id}.png'\n",
    "    plt.savefig(fig1)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    counts_min.plot(kind='bar', width=0.8)\n",
    "    plt.title(f'ETA rows per minute - {stop_id}')\n",
    "    plt.ylabel('rows')\n",
    "    plt.xlabel('snapshot_min')\n",
    "    plt.tight_layout()\n",
    "    fig2 = ANALYSIS_DIR / f'counts_per_minute_{stop_id}.png'\n",
    "    plt.savefig(fig2)\n",
    "    plt.close()\n",
    "\n",
    "    summary[stop_id] = {\n",
    "        'rows': int(len(g)),\n",
    "        'snapshots': int(g['snapshot_min'].nunique()),\n",
    "        'mean_wait_s': float(g['wait_s'].mean()),\n",
    "        'median_wait_s': float(g['wait_s'].median()),\n",
    "        'min_wait_s': float(g['wait_s'].min()),\n",
    "        'max_wait_s': float(g['wait_s'].max()),\n",
    "        'mean_wait_per_min_csv': str(fig1.name),\n",
    "        'counts_per_min_csv': str(fig2.name),\n",
    "    }\n",
    "\n",
    "# combined trend: mean wait per minute for each stop in one plot\n",
    "plt.figure(figsize=(10,5))\n",
    "for stop_id, g in df.groupby('queried_stop_id'):\n",
    "    per_min = g.groupby('snapshot_min')['wait_s'].mean()\n",
    "    per_min.plot(label=stop_id)\n",
    "plt.legend()\n",
    "plt.title('Mean wait per minute (by stop)')\n",
    "plt.ylabel('mean wait (s)')\n",
    "plt.xlabel('snapshot_min')\n",
    "plt.tight_layout()\n",
    "combined_fig = ANALYSIS_DIR / 'combined_wait_trend.png'\n",
    "plt.savefig(combined_fig)\n",
    "plt.close()\n",
    "summary['combined_wait_trend'] = str(combined_fig.name)\n",
    "\n",
    "# ETA-seq distribution (hist by seq)\n",
    "plt.figure(figsize=(8,5))\n",
    "for seq in sorted(df['eta_seq'].unique()):\n",
    "    subset = df[df['eta_seq']==seq]\n",
    "    plt.hist(subset['wait_s'].dropna(), bins=30, alpha=0.5, label=f'eta_seq={int(seq)}')\n",
    "plt.legend()\n",
    "plt.title('Wait time distribution by eta_seq')\n",
    "plt.xlabel('wait seconds')\n",
    "plt.ylabel('count')\n",
    "plt.tight_layout()\n",
    "seq_fig = ANALYSIS_DIR / 'wait_hist_by_eta_seq.png'\n",
    "plt.savefig(seq_fig)\n",
    "plt.close()\n",
    "summary['wait_hist_by_eta_seq'] = str(seq_fig.name)\n",
    "\n",
    "# save summary JSON\n",
    "with open(ANALYSIS_DIR / 'analysis_summary.json','w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print('Analysis outputs written to', ANALYSIS_DIR)\n",
    "print('Files:', [p.name for p in sorted(ANALYSIS_DIR.iterdir())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61843a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m csv_dir = Path(\u001b[34;43m__file__\u001b[39;49m).parent / \u001b[33m'\u001b[39m\u001b[33mmonitor_outputs_60min\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m csv_files = \u001b[38;5;28msorted\u001b[39m(csv_dir.glob(\u001b[33m'\u001b[39m\u001b[33mmonitor_summary_*.csv\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m csv_files:\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "csv_dir = Path(__file__).parent / 'monitor_outputs_60min'\n",
    "csv_files = sorted(csv_dir.glob('monitor_summary_*.csv'))\n",
    "if not csv_files:\n",
    "    print('No monitor_summary CSV found')\n",
    "    raise SystemExit(1)\n",
    "path = csv_files[-1]\n",
    "\n",
    "df = pd.read_csv(path, parse_dates=['snapshot_ts','eta','data_timestamp'])\n",
    "# normalize timezone awareness if needed\n",
    "if df['snapshot_ts'].dt.tz is None:\n",
    "    df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts']).dt.tz_localize('UTC')\n",
    "if df['eta'].dt.tz is None:\n",
    "    df['eta'] = pd.to_datetime(df['eta']).dt.tz_localize('Asia/Hong_Kong')\n",
    "\n",
    "summary = {}\n",
    "summary['csv_file'] = str(path.name)\n",
    "summary['total_rows'] = len(df)\n",
    "summary['unique_snapshots'] = df['snapshot_ts'].nunique()\n",
    "summary['first_snapshot'] = df['snapshot_ts'].min()\n",
    "summary['last_snapshot'] = df['snapshot_ts'].max()\n",
    "summary['rows_per_stop'] = df['queried_stop_id'].value_counts().to_dict()\n",
    "summary['distinct_routes_per_stop'] = df.groupby('queried_stop_id')['route'].nunique().to_dict()\n",
    "\n",
    "# compute wait seconds = (eta - snapshot_ts).total_seconds()\n",
    "df['wait_s'] = (df['eta'].dt.tz_convert('Asia/Hong_Kong') - df['snapshot_ts'].dt.tz_convert('Asia/Hong_Kong')).dt.total_seconds()\n",
    "agg_df = df.groupby('queried_stop_id')['wait_s'].agg(['count','mean','median','min','max'])\n",
    "summary['wait_stats_per_stop'] = {}\n",
    "for stop_id, row in agg_df.iterrows():\n",
    "    summary['wait_stats_per_stop'][stop_id] = {\n",
    "        'count': int(row['count']),\n",
    "        'mean_s': float(row['mean']) if not pd.isna(row['mean']) else None,\n",
    "        'median_s': float(row['median']) if not pd.isna(row['median']) else None,\n",
    "        'min_s': float(row['min']) if not pd.isna(row['min']) else None,\n",
    "        'max_s': float(row['max']) if not pd.isna(row['max']) else None,\n",
    "    }\n",
    "\n",
    "# print a readable report\n",
    "print('Monitor summary file:', summary['csv_file'])\n",
    "print('Total rows:', summary['total_rows'])\n",
    "print('Snapshots:', summary['unique_snapshots'], 'from', summary['first_snapshot'], 'to', summary['last_snapshot'])\n",
    "print('\\nRows per stop:')\n",
    "for s,c in summary['rows_per_stop'].items():\n",
    "    print('  ', s, c)\n",
    "print('\\nDistinct routes per stop:')\n",
    "for s,r in summary['distinct_routes_per_stop'].items():\n",
    "    print('  ', s, r)\n",
    "print('\\nWait time (seconds) stats per stop:')\n",
    "for s,stats in summary['wait_stats_per_stop'].items():\n",
    "    print(f\"  {s}: count={stats['count']}, mean={stats['mean_s']:.1f}s, median={stats['median_s']:.1f}s, min={stats['min_s']:.1f}s, max={stats['max_s']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b30bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
